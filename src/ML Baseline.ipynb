{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import sys\n",
    "from scipy import sparse\n",
    "\n",
    "target_columns = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "           'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "           'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "           'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "           'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "           'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "           'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "           'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_no_interactions = 0\n",
    "array_ordered = np.arange(1, 25)\n",
    "def evaluate_sample(predictions, y_true, k):\n",
    "    global total_no_interactions\n",
    "    global array_ordered\n",
    "    sorted_pred, sorted_y = zip(*sorted(zip(predictions, y_true[0]), reverse=True )) #TODO: Discard the products that were already part of the portfolio in the last step\n",
    "    #Recall at k\n",
    "    true_pos_k = sum(sorted_y[0:k])\n",
    "    num_pos = sum(y_true[0])\n",
    "    recall_user = (true_pos_k/float(num_pos))\n",
    "    #Map at k\n",
    "    precisions = sorted_y/array_ordered\n",
    "    sum_precisions = np.sum(precisions[:k])\n",
    "    if num_pos == 0:\n",
    "        map_k = 0\n",
    "        recall_user = 0\n",
    "        total_no_interactions += 1\n",
    "    else:\n",
    "        map_k = sum_precisions/float(min(num_pos, k))\n",
    "        #map_k = sum_precisions/float(k)\n",
    "\n",
    "    #print('sorted_pred: ' + str(sorted_pred))\n",
    "    #print('sorted_y: ' + str(sorted_y))\n",
    "    #print('true_pos_k: ' + str(true_pos_k))\n",
    "    #print('num_pos: ' + str(num_pos))\n",
    "    #print('recall_user: ' + str(recall_user))\n",
    "    #print('precisions: ' + str(precisions))\n",
    "    #print('sum_precisions: ' + str(sum_precisions))\n",
    "    #print('map_k: ' + str(map_k))\n",
    "    \n",
    "\n",
    "\n",
    "    return recall_user, true_pos_k, num_pos, map_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "representation = 4\n",
    "max_interactions = 5\n",
    "padding = 'right'\n",
    "aux_features_length = '0'\n",
    "with open('pickles/X_train_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length +  '.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "with open('pickles/X_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "with open('pickles/Y_train_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    Y_train = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_features = X_train[0].shape[0] * X_train[0].shape[1]\n",
    "num_output = Y_train[0].shape[1]\n",
    "X_train_no_sparse = np.zeros((len(X_train), num_features), dtype=np.int8)\n",
    "Y_train_no_sparse = np.zeros((len(Y_train), num_output), dtype=np.int8)\n",
    "for i in range(len(X_train)):\n",
    "    X_train_no_sparse[i] = X_train[i].toarray().reshape(num_features)\n",
    "    Y_train_no_sparse[i] = Y_train[i].toarray().reshape(num_output)\n",
    "X_train_no_sparse = sparse.csr_matrix(X_train_no_sparse, dtype=np.int8)\n",
    "Y_train_no_sparse = sparse.csr_matrix(Y_train_no_sparse, dtype=np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_no_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train_no_sparse.toarray(), Y_train_no_sparse.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_no_sparse.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/X_local_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    X_local_test = pickle.load(handle)\n",
    "with open('pickles/Y_local_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    Y_local_test = pickle.load(handle)\n",
    "X_local_test = np.array(X_local_test)\n",
    "Y_local_test = np.array(Y_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_no_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_no_sparse = np.zeros((len(X_local_test), num_features), dtype=np.int8)\n",
    "Y_test_no_sparse = np.zeros((len(Y_local_test), num_output), dtype=np.int8)\n",
    "for i in range(len(X_local_test)):\n",
    "    X_test_no_sparse[i] = X_local_test[i].reshape(num_features)\n",
    "    Y_test_no_sparse[i] = Y_local_test[i].reshape(num_output)\n",
    "X_test_no_sparse = sparse.csr_matrix(X_test_no_sparse, dtype=np.int8)\n",
    "Y_test_no_sparse = sparse.csr_matrix(Y_test_no_sparse, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_local_test = clf.predict_proba(X_test_no_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_no_sparse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pred_local_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_local_test = np.array(X_local_test)\n",
    "Y_local_test = np.array(Y_local_test)\n",
    "k = 7\n",
    "with open('pickles/indices_interactions_local_test.pickle', 'rb') as handle:\n",
    "    indices_interactions = pickle.load(handle)\n",
    "recall_users = []\n",
    "total_true_pos_k = 0\n",
    "total_pos = 0\n",
    "with open('pickles/indices_interactions_local_test.pickle', 'rb') as handle:\n",
    "    indices_interactions = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(pred_local_test)):\n",
    "    if i in indices_interactions:\n",
    "        #sorted_pred, sorted_y = zip(*sorted(zip(pred_local_test[i], X_local_test[i]), reverse=True ))\n",
    "        recall_user, true_pos_k, num_pos, map_k = evaluate_sample(pred_local_test[i], Y_local_test[i], k)\n",
    "        recall_users.append(recall_user)\n",
    "        total_true_pos_k += true_pos_k\n",
    "        total_pos += num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Results local test:')\n",
    "print('Total users evaluated: ' + str(len(recall_users)))\n",
    "print('Total True positives at k: :' + str(total_true_pos_k))\n",
    "print('Total True positives: ' + str(total_pos))\n",
    "recall_k = total_true_pos_k/ float(total_pos)\n",
    "print('Total Recall at ' + str(k) + ': ' + str(recall_k))\n",
    "print('Mean recall at ' + str(k) + ' by user: ' + str(np.mean(recall_users)))\n",
    "print('Mean map at ' + str(k) + ' by user: ' + str(map_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/sorted_freq.pickle', 'rb') as handle:\n",
    "    sorted_freq = pickle.load(handle)\n",
    "with open('pickles/sorted_prods_total.pickle', 'rb') as handle:\n",
    "    sorted_prods_total = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_freq = np.zeros(24)\n",
    "for i in range(len(sorted_freq)):\n",
    "    idx_product = target_columns.index(sorted_prods_total[i])\n",
    "    prob_product = sorted_freq[i]\n",
    "    target_freq[idx_product] = prob_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recall_users = []\n",
    "map_k_users = []\n",
    "total_true_pos_k = 0\n",
    "total_pos = 0\n",
    "k = 7\n",
    "for i in range(len(Y_local_test)):\n",
    "    recall_user, true_pos_k, num_pos, map_k = evaluate_sample(target_freq, Y_local_test[i], k)\n",
    "    map_k_users.append(map_k)\n",
    "    recall_users.append(recall_user)\n",
    "    total_true_pos_k += true_pos_k\n",
    "    total_pos += num_pos\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Results local test BASELINE:')\n",
    "print('Total users evaluated: ' + str(len(recall_users)))\n",
    "print('Total True positives at k: :' + str(total_true_pos_k))\n",
    "print('Total True positives: ' + str(total_pos))\n",
    "recall_k = total_true_pos_k/ float(total_pos)\n",
    "print('Total Recall at ' + str(k) + ': ' + str(recall_k))\n",
    "print('Mean recall at ' + str(k) + ' by user: ' + str(np.mean(recall_users)))\n",
    "print('Mean map at ' + str(k) + ' by user: ' + str(np.mean(map_k_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using one vs Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "representation = 4\n",
    "max_interactions = 5\n",
    "padding = 'right'\n",
    "aux_features_length = '0'\n",
    "with open('pickles/X_train_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length +  '.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "with open('pickles/X_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "with open('pickles/Y_train_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    Y_train = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = X_train[0].shape[0] * X_train[0].shape[1]\n",
    "num_output = Y_train[0].shape[1]\n",
    "X_train_no_sparse = np.zeros((len(X_train), num_features), dtype=np.int8)\n",
    "Y_train_no_sparse = np.zeros((len(Y_train), num_output), dtype=np.int8)\n",
    "for i in range(len(X_train)):\n",
    "    X_train_no_sparse[i] = X_train[i].toarray().reshape(num_features)\n",
    "    Y_train_no_sparse[i] = Y_train[i].toarray().reshape(num_output)\n",
    "X_train_no_sparse = sparse.csr_matrix(X_train_no_sparse, dtype=np.int8)\n",
    "Y_train_no_sparse = sparse.csr_matrix(Y_train_no_sparse, dtype=np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:70: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classif = OneVsRestClassifier(LogisticRegression(penalty='l2', tol=0.0001, C=1.0, random_state=17, max_iter=100,  verbose=0))\n",
    "#classif = OneVsRestClassifier(LogisticRegression(penalty='l2', tol=0.0001, C=10.0, random_state=17, max_iter=100,  verbose=0))\n",
    "#classif = OneVsRestClassifier(LogisticRegression(penalty='l2', tol=0.0001, C=0.1, random_state=17, max_iter=100,  verbose=0))\n",
    "#classif = OneVsRestClassifier(ExtraTreesClassifier(n_estimators=40, max_depth=30, random_state=17))\n",
    "#classif = OneVsRestClassifier(SVC(kernel='rbf', probability=True))\n",
    "classif.fit(X_train_no_sparse, Y_train_no_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/X_local_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    X_local_test = pickle.load(handle)\n",
    "with open('pickles/Y_local_test_rep' + str(representation) + '_' + str(max_interactions) + '_' + padding + '_' + aux_features_length + '.pickle', 'rb') as handle:\n",
    "    Y_local_test = pickle.load(handle)\n",
    "X_local_test = np.array(X_local_test)\n",
    "Y_local_test = np.array(Y_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_no_sparse = np.zeros((len(X_local_test), num_features), dtype=np.int8)\n",
    "Y_test_no_sparse = np.zeros((len(Y_local_test), num_output), dtype=np.int8)\n",
    "for i in range(len(X_local_test)):\n",
    "    X_test_no_sparse[i] = X_local_test[i].reshape(num_features)\n",
    "    Y_test_no_sparse[i] = Y_local_test[i].reshape(num_output)\n",
    "X_test_no_sparse = sparse.csr_matrix(X_test_no_sparse, dtype=np.int8)\n",
    "Y_test_no_sparse = sparse.csr_matrix(Y_test_no_sparse, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = classif.predict_proba(X_test_no_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23093, 24)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-------------------\n",
      "Results local test for k = 1:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :19263\n",
      "Total True positives: 29573\n",
      "Total Recall at 1: 0.651371183174\n",
      "Mean recall at 1 by user: 0.728583697802\n",
      "Mean map at 1 by user: 0.834148876283\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 2:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :25074\n",
      "Total True positives: 29573\n",
      "Total Recall at 2: 0.847867987691\n",
      "Mean recall at 2 by user: 0.870820161954\n",
      "Mean map at 2 by user: 0.808470099164\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 3:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :26867\n",
      "Total True positives: 29573\n",
      "Total Recall at 3: 0.908497616069\n",
      "Mean recall at 3 by user: 0.916217757185\n",
      "Mean map at 3 by user: 0.815388982712\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 4:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :27691\n",
      "Total True positives: 29573\n",
      "Total Recall at 4: 0.936360869712\n",
      "Mean recall at 4 by user: 0.939406602289\n",
      "Mean map at 4 by user: 0.820661443824\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 5:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :28290\n",
      "Total True positives: 29573\n",
      "Total Recall at 5: 0.956615832009\n",
      "Mean recall at 5 by user: 0.957119040402\n",
      "Mean map at 5 by user: 0.82417416052\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 6:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :28818\n",
      "Total True positives: 29573\n",
      "Total Recall at 6: 0.974469955703\n",
      "Mean recall at 6 by user: 0.974539903867\n",
      "Mean map at 6 by user: 0.827077637764\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 7:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :29094\n",
      "Total True positives: 29573\n",
      "Total Recall at 7: 0.983802793088\n",
      "Mean recall at 7 by user: 0.983509432873\n",
      "Mean map at 7 by user: 0.828358999051\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 8:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :29257\n",
      "Total True positives: 29573\n",
      "Total Recall at 8: 0.989314577486\n",
      "Mean recall at 8 by user: 0.989266588721\n",
      "Mean map at 8 by user: 0.829078643532\n",
      "Total no interactions: 0\n",
      "0\n",
      "-------------------\n",
      "Results local test for k = 9:\n",
      "Total users evaluated: 23093\n",
      "Total True positives at k: :29342\n",
      "Total True positives: 29573\n",
      "Total Recall at 9: 0.992188820884\n",
      "Mean recall at 9 by user: 0.992012731131\n",
      "Mean map at 9 by user: 0.829383770466\n",
      "Total no interactions: 0\n"
     ]
    }
   ],
   "source": [
    "recalls_model = []\n",
    "recalls_baseline = []\n",
    "maps_model = []\n",
    "maps_baseline = []\n",
    "ks = [1,2,3,4,5,6,7,8,9]\n",
    "for k in ks:\n",
    "    recall_users = []\n",
    "    map_k_users = []\n",
    "    total_true_pos_k = 0\n",
    "    total_pos = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(probs)):  \n",
    "        #sorted_pred, sorted_y = zip(*sorted(zip(pred_local_test[i], Y_local_test[i]), reverse=True )) #TODO: Discard the products that were already part of the portfolio in the last step\n",
    "        recall_user, true_pos_k, num_pos, map_k = evaluate_sample(probs[i], Y_test_no_sparse[i].toarray(), k)\n",
    "        map_k_users.append(map_k)\n",
    "        recall_users.append(recall_user)\n",
    "        total_true_pos_k += true_pos_k\n",
    "        total_pos += num_pos\n",
    "        if i % 100000 == 0:\n",
    "            print(i)\n",
    "                \n",
    "    print('-------------------')            \n",
    "    print('Results local test for k = ' + str(k) + ':')\n",
    "    print('Total users evaluated: ' + str(len(recall_users)))\n",
    "    print('Total True positives at k: :' + str(total_true_pos_k))\n",
    "    print('Total True positives: ' + str(total_pos))\n",
    "    recall_k = total_true_pos_k/ float(total_pos)\n",
    "    print('Total Recall at ' + str(k) + ': ' + str(recall_k))\n",
    "    print('Mean recall at ' + str(k) + ' by user: ' + str(np.mean(recall_users)))\n",
    "    print('Mean map at ' + str(k) + ' by user: ' + str(np.mean(map_k_users)))\n",
    "    #print('Max map at ' + str(k) + ' by user: ' + str(np.max(map_k_users)))   \n",
    "    #print('Min map at ' + str(k) + ' by user: ' + str(np.min(map_k_users))) \n",
    "    print('Total no interactions: ' + str(total_no_interactions))\n",
    "    recalls_model.append(np.mean(recall_users))\n",
    "    maps_model.append(np.mean(map_k_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0], dtype=int8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_no_sparse[0].toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
